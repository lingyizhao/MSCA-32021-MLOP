{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.35.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from azureml.core import Dataset\n",
    "\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PipelineRun, StepRun, PortDataReference\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.core.model import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('SDK Version:', azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = Workspace.create(name='MLOP_17',\n",
    "#                subscription_id='6d705e60-c254-4179-9abe-b484e8ac71ef',\n",
    "#                resource_group='MLOP',\n",
    "#                create_resource_group=False,\n",
    "#                location='eastus'\n",
    "#                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading /Users/lingyizhao/Desktop/mlop/project/clean_data.csv\n",
      "Uploaded /Users/lingyizhao/Desktop/mlop/project/clean_data.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a73222b0b855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        show_progress=True)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtab_data_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_delimited_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/clean_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Registering the Dataset with the workspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/data/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activity_info'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/data/dataset_factory.py\u001b[0m in \u001b[0;36mfrom_delimited_files\u001b[0;34m(path, validate, include_path, infer_column_types, set_column_types, separator, header, partition_format, support_multi_line, empty_as_string, encoding)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            encoding=encoding)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         dataflow = _transform_and_validate(\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mdataflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/data/dataset_factory.py\u001b[0m in \u001b[0;36m_transform_and_validate\u001b[0;34m(dataflow, partition_format, include_path, validate, infer_column_types)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mdataflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m         _validate_has_data(dataflow, 'Cannot load any data from the specified path. '\n\u001b[0m\u001b[1;32m   1168\u001b[0m                                      'Make sure the path is accessible and contains data.')\n\u001b[1;32m   1169\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minfer_column_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/data/dataset_error_handling.py\u001b[0m in \u001b[0;36m_validate_has_data\u001b[0;34m(dataflow, error_message)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mensure_dataflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify_has_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     except (dataprep().api.dataflow.DataflowValidationError,\n\u001b[1;32m     67\u001b[0m             dataprep().api.errorhandlers.ExecutionError) as e:\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/dataprep/api/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_ACTIVITY_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mactivityLogger\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivityLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mACTIVITY_INFO_KEY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mERROR_CODE_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/dataprep/api/dataflow.py\u001b[0m in \u001b[0;36mverify_has_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEmptyStepsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_pyrecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mDataflowValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The Dataflow produced no records.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/dataprep/api/dataflow.py\u001b[0m in \u001b[0;36m_to_pyrecords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing_secrets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m                 self._engine_api.execute_anonymous_activity(\n\u001b[0m\u001b[1;32m    791\u001b[0m                     ExecuteAnonymousActivityMessageArguments(\n\u001b[1;32m    792\u001b[0m                         \u001b[0manonymous_activity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataflow_to_anonymous_activity_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataflow_to_execute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/dataprep/api/_aml_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mengine_api_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_environment_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msend_message_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/api.py\u001b[0m in \u001b[0;36mexecute_anonymous_activity\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mupdate_aml_env_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_engine_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_anonymous_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtypedefinitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecuteAnonymousActivityMessageArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCancellationToken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Engine.ExecuteActivity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/azureml/dataprep/api/engineapi/engine.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    269\u001b[0m         }, cls=CustomEncoder))\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_messages_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pending_messages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #Check and List the datasets attached to our Workspace\n",
    "# from azureml.core import Dataset\n",
    "\n",
    "    \n",
    "# #Upload your own data\n",
    "\n",
    "# default_ds.upload_files(files=['/Users/lingyizhao/Desktop/mlop/project/clean_data.csv'], \n",
    "#                        target_path='telecom-data/', # Put it in a folder path in the datastore\n",
    "#                        overwrite=True, # Replace existing files of the same name\n",
    "#                        show_progress=True)\n",
    "\n",
    "# tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds.path('./data/clean_data.csv')))\n",
    "\n",
    "# # Registering the Dataset with the workspace\n",
    "# tab_data_set = tab_data_set.register(ws, 'telecom_data',create_new_version = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading /Users/lingyizhao/Desktop/mlop/project/clean_data_v2.csv\n",
      "Uploaded /Users/lingyizhao/Desktop/mlop/project/clean_data_v2.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "#Check and List the datasets attached to our Workspace\n",
    "from azureml.core import Dataset\n",
    "\n",
    "    \n",
    "#Upload your own data\n",
    "\n",
    "default_ds.upload_files(files=['/Users/lingyizhao/Desktop/mlop/project/clean_data_v2.csv'], \n",
    "                       target_path='telecom-data-2/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)\n",
    "\n",
    "tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'telecom-data-2/*.csv'))\n",
    "\n",
    "\n",
    "# Registering the Dataset with the workspace\n",
    "tab_data_set = tab_data_set.register(ws, 'telecom_data',create_new_version = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account_length</th>\n",
       "      <th>area_code</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>intl_plan</th>\n",
       "      <th>voice_mail_plan</th>\n",
       "      <th>total_day_calls</th>\n",
       "      <th>total_eve_minutes</th>\n",
       "      <th>total_eve_calls</th>\n",
       "      <th>total_eve_charge</th>\n",
       "      <th>total_night_minutes</th>\n",
       "      <th>total_night_calls</th>\n",
       "      <th>total_night_charge</th>\n",
       "      <th>total_intl_minutes</th>\n",
       "      <th>total_intl_calls</th>\n",
       "      <th>total_intl_charge</th>\n",
       "      <th>number_customer_service_calls</th>\n",
       "      <th>churned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>110</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>123</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>114</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>71</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>113</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>HI</td>\n",
       "      <td>50</td>\n",
       "      <td>408</td>\n",
       "      <td>365-8751</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>127</td>\n",
       "      <td>223.0</td>\n",
       "      <td>126</td>\n",
       "      <td>18.96</td>\n",
       "      <td>297.5</td>\n",
       "      <td>116</td>\n",
       "      <td>13.39</td>\n",
       "      <td>9.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>WV</td>\n",
       "      <td>152</td>\n",
       "      <td>415</td>\n",
       "      <td>334-9736</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>90</td>\n",
       "      <td>256.8</td>\n",
       "      <td>73</td>\n",
       "      <td>21.83</td>\n",
       "      <td>213.6</td>\n",
       "      <td>113</td>\n",
       "      <td>9.61</td>\n",
       "      <td>14.7</td>\n",
       "      <td>2</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>DC</td>\n",
       "      <td>61</td>\n",
       "      <td>415</td>\n",
       "      <td>333-6861</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>89</td>\n",
       "      <td>172.8</td>\n",
       "      <td>128</td>\n",
       "      <td>14.69</td>\n",
       "      <td>212.4</td>\n",
       "      <td>97</td>\n",
       "      <td>9.56</td>\n",
       "      <td>13.6</td>\n",
       "      <td>4</td>\n",
       "      <td>3.67</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>DC</td>\n",
       "      <td>109</td>\n",
       "      <td>510</td>\n",
       "      <td>394-2206</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>67</td>\n",
       "      <td>171.7</td>\n",
       "      <td>92</td>\n",
       "      <td>14.59</td>\n",
       "      <td>224.4</td>\n",
       "      <td>89</td>\n",
       "      <td>10.10</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>VT</td>\n",
       "      <td>86</td>\n",
       "      <td>415</td>\n",
       "      <td>373-8058</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>102</td>\n",
       "      <td>267.1</td>\n",
       "      <td>104</td>\n",
       "      <td>22.70</td>\n",
       "      <td>154.8</td>\n",
       "      <td>100</td>\n",
       "      <td>6.97</td>\n",
       "      <td>9.3</td>\n",
       "      <td>16</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account_length  area_code phone_number intl_plan voice_mail_plan  \\\n",
       "0       KS             128        415     382-4657        no             yes   \n",
       "1       OH             107        415     371-7191        no             yes   \n",
       "2       NJ             137        415     358-1921        no              no   \n",
       "3       OH              84        408     375-9999       yes              no   \n",
       "4       OK              75        415     330-6626       yes              no   \n",
       "...    ...             ...        ...          ...       ...             ...   \n",
       "4995    HI              50        408     365-8751        no             yes   \n",
       "4996    WV             152        415     334-9736        no              no   \n",
       "4997    DC              61        415     333-6861        no              no   \n",
       "4998    DC             109        510     394-2206        no              no   \n",
       "4999    VT              86        415     373-8058        no             yes   \n",
       "\n",
       "      total_day_calls  total_eve_minutes  total_eve_calls  total_eve_charge  \\\n",
       "0                 110              197.4               99             16.78   \n",
       "1                 123              195.5              103             16.62   \n",
       "2                 114              121.2              110             10.30   \n",
       "3                  71               61.9               88              5.26   \n",
       "4                 113              148.3              122             12.61   \n",
       "...               ...                ...              ...               ...   \n",
       "4995              127              223.0              126             18.96   \n",
       "4996               90              256.8               73             21.83   \n",
       "4997               89              172.8              128             14.69   \n",
       "4998               67              171.7               92             14.59   \n",
       "4999              102              267.1              104             22.70   \n",
       "\n",
       "      total_night_minutes  total_night_calls  total_night_charge  \\\n",
       "0                   244.7                 91               11.01   \n",
       "1                   254.4                103               11.45   \n",
       "2                   162.6                104                7.32   \n",
       "3                   196.9                 89                8.86   \n",
       "4                   186.9                121                8.41   \n",
       "...                   ...                ...                 ...   \n",
       "4995                297.5                116               13.39   \n",
       "4996                213.6                113                9.61   \n",
       "4997                212.4                 97                9.56   \n",
       "4998                224.4                 89               10.10   \n",
       "4999                154.8                100                6.97   \n",
       "\n",
       "      total_intl_minutes  total_intl_calls  total_intl_charge  \\\n",
       "0                   10.0                 3               2.70   \n",
       "1                   13.7                 3               3.70   \n",
       "2                   12.2                 5               3.29   \n",
       "3                    6.6                 7               1.78   \n",
       "4                   10.1                 3               2.73   \n",
       "...                  ...               ...                ...   \n",
       "4995                 9.9                 5               2.67   \n",
       "4996                14.7                 2               3.97   \n",
       "4997                13.6                 4               3.67   \n",
       "4998                 8.5                 6               2.30   \n",
       "4999                 9.3                16               2.51   \n",
       "\n",
       "      number_customer_service_calls  churned  \n",
       "0                                 1    False  \n",
       "1                                 1    False  \n",
       "2                                 0    False  \n",
       "3                                 2    False  \n",
       "4                                 3    False  \n",
       "...                             ...      ...  \n",
       "4995                              2    False  \n",
       "4996                              3     True  \n",
       "4997                              1    False  \n",
       "4998                              0    False  \n",
       "4999                              0    False  \n",
       "\n",
       "[5000 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataframe\n",
    "tab_data_set.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create scripts for pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "telecom_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'telecom_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting telecom_pipeline/prep_telecom.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/prep_telecom.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "telecom = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# Log raw row count\n",
    "row_count = (len(telecom))\n",
    "run.log('raw_rows', row_count)\n",
    "\n",
    "# data cleaning\n",
    "telecom = telecom.dropna()\n",
    "\n",
    "telecom['voice_mail_plan'] = telecom['voice_mail_plan'].map(lambda x: x.strip())\n",
    "telecom['intl_plan'] = telecom['intl_plan'].map(lambda x: x.strip())\n",
    "telecom['churned'] = telecom['churned'].astype('str') \n",
    "telecom['churned'] = telecom['churned'].map(lambda x: x.strip())\n",
    "telecom = telecom.replace(['True.', 'False.'], ['True','False']) \n",
    "\n",
    "\n",
    "# Log processed rows\n",
    "row_count = (len(telecom))\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "# Save the prepped data\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder,'data.csv')\n",
    "telecom.to_csv(save_path, index=False, header=True)\n",
    "\n",
    "# End the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting telecom_pipeline/train_lr.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/train_lr.py\n",
    "# Import libraries\n",
    "from azureml.core import Run, Model\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--training-folder\", type=str, dest='training_folder', help='training data folder')\n",
    "args = parser.parse_args()\n",
    "training_folder = args.training_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the prepared data file in the training folder\n",
    "print(\"Loading Data...\")\n",
    "file_path = os.path.join(training_folder,'data.csv')\n",
    "telecom = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "y = np.where(telecom['churned'] == 'True',1,0)\n",
    "## Drop some useless columns\n",
    "to_drop = ['state','area_code','phone_number','churned']\n",
    "churn_feat_space = telecom.drop(to_drop, axis=1)\n",
    "## converted yes and no\n",
    "yes_no_cols = [\"intl_plan\",\"voice_mail_plan\"]\n",
    "churn_feat_space[yes_no_cols] = churn_feat_space[yes_no_cols] == 'yes'\n",
    "X = churn_feat_space\n",
    "\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Scale the data, using standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Train the random forest model\n",
    "# Possible hyperparamter options for Logistic Regression Regularization\n",
    "# Penalty is choosed from L1 or L2\n",
    "# C is the lambda value(weight) for L1 and L2\n",
    "parameters = {\n",
    "    'penalty':('l1', 'l2'), \n",
    "    'C':(1, 5, 10)\n",
    "}\n",
    "Grid_LR = GridSearchCV(LogisticRegression(),parameters, cv=5)\n",
    "Grid_LR.fit(X_train, y_train)\n",
    "\n",
    "# best model\n",
    "best_LR_model = Grid_LR.best_estimator_\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = best_LR_model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = best_LR_model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "run.log_image(name = \"ROC\", plot = fig)\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "print(\"Saving model...\")\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model_file = os.path.join('outputs', 'logistic_model.pkl')\n",
    "joblib.dump(value=best_LR_model, filename=model_file)\n",
    "\n",
    "# Register the model\n",
    "print('Registering model...')\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'logistic_model',\n",
    "               tags={'Training context':'Pipeline'},\n",
    "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
    "\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting telecom_pipeline/train_rf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/train_rf.py\n",
    "# Import libraries\n",
    "from azureml.core import Run, Model\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--training-folder\", type=str, dest='training_folder', help='training data folder')\n",
    "args = parser.parse_args()\n",
    "training_folder = args.training_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the prepared data file in the training folder\n",
    "print(\"Loading Data...\")\n",
    "file_path = os.path.join(training_folder,'data.csv')\n",
    "telecom = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "y = np.where(telecom['churned'] == 'True',1,0)\n",
    "## Drop some useless columns\n",
    "to_drop = ['state','area_code','phone_number','churned']\n",
    "churn_feat_space = telecom.drop(to_drop, axis=1)\n",
    "## converted yes and no\n",
    "yes_no_cols = [\"intl_plan\",\"voice_mail_plan\"]\n",
    "churn_feat_space[yes_no_cols] = churn_feat_space[yes_no_cols] == 'yes'\n",
    "X = churn_feat_space\n",
    "\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "# Scale the data, using standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Train the random forest model\n",
    "# Possible hyperparamter options for Random Forest\n",
    "# Choose the number of trees\n",
    "parameters = {\n",
    "    'n_estimators' : [40,60,80]\n",
    "}\n",
    "Grid_RF = GridSearchCV(RandomForestClassifier(),parameters, cv=5)\n",
    "Grid_RF.fit(X_train, y_train)\n",
    "\n",
    "# best random forest\n",
    "best_RF_model = Grid_RF.best_estimator_\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = best_RF_model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = best_RF_model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "run.log_image(name = \"ROC\", plot = fig)\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "print(\"Saving model...\")\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model_file = os.path.join('outputs', 'randomforest_model.pkl')\n",
    "joblib.dump(value=best_RF_model, filename=model_file)\n",
    "\n",
    "# Register the model\n",
    "print('Registering model...')\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'randomforest_model',\n",
    "               tags={'Training context':'Pipeline'},\n",
    "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
    "\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a compute environment for the pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"mlop-test\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "telecom_env = Environment(\"telecom-pipeline-env\")\n",
    "\n",
    "# Create a set of package dependencies\n",
    "telecom_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],\n",
    "                                             pip_packages=['azureml-defaults','azureml-dataprep[pandas]','pyarrow'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "telecom_env.python.conda_dependencies = telecom_packages\n",
    "\n",
    "# Register the environment \n",
    "telecom_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'telecom-pipeline-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Get the training dataset\n",
    "telecom_ds = ws.datasets.get(\"telecom dataset\")\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "prepped_data_folder = PipelineData(\"prepped_data_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "# Step 1, Run the data prep script\n",
    "train_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"prep_telecom.py\",\n",
    "                                arguments = ['--input-data', telecom_ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data_folder],\n",
    "                                outputs=[prepped_data_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "# Step 2, run the training script\n",
    "register_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"train_rf.py\",\n",
    "                                arguments = ['--training-folder', prepped_data_folder],\n",
    "                                inputs=[prepped_data_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Prepare Data [64608749][880b1623-cd7c-4a40-9ece-9f6d512145be], (This step will run and generate new outputs)Created step Train and Register Model [5ee5571b][b9b0fba6-d1aa-4d02-b35d-998a29b1f5da], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun 77ca1a29-67ff-41fd-842d-11f5761c3727\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/77ca1a29-67ff-41fd-842d-11f5761c3727?wsid=/subscriptions/6d705e60-c254-4179-9abe-b484e8ac71ef/resourcegroups/MLOP/workspaces/MLOP_16&tid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45850cfad0f4bc79bd5dc21de054708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/77ca1a29-67ff-41fd-842d-11f5761c3727?wsid=/subscriptions/6d705e60-c254-4179-9abe-b484e8ac71ef/resourcegroups/MLOP/workspaces/MLOP_16&tid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6\", \"run_id\": \"77ca1a29-67ff-41fd-842d-11f5761c3727\", \"run_properties\": {\"run_id\": \"77ca1a29-67ff-41fd-842d-11f5761c3727\", \"created_utc\": \"2021-11-04T03:15:59.655803Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2021-11-04T03:20:11.525167Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.77ca1a29-67ff-41fd-842d-11f5761c3727/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=dKKReS5j8xMwrtr9RxwC9Xgfp%2BMPUSHeMiIQX%2Bxe%2FJw%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A34%3A48Z&ske=2021-11-05T08%3A44%3A48Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A16%3A32Z&se=2021-11-04T11%3A26%3A32Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.77ca1a29-67ff-41fd-842d-11f5761c3727/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=zzCm9q2kr7hIaEFd8myRKpLrbDlpji8wtBVNxfYamYs%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A34%3A48Z&ske=2021-11-05T08%3A44%3A48Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A16%3A32Z&se=2021-11-04T11%3A26%3A32Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.77ca1a29-67ff-41fd-842d-11f5761c3727/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=QrqbVwbLGoDaG5IWEeZP8iTWYm9o%2FMHoTuh1FIZfAII%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A34%3A48Z&ske=2021-11-05T08%3A44%3A48Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A16%3A32Z&se=2021-11-04T11%3A26%3A32Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:04:11\", \"run_number\": \"17\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-11-04T03:16:18.770104Z\", \"created_time\": \"2021-11-04T03:16:01.827809Z\", \"end_time\": \"2021-11-04T03:16:59.194981Z\", \"duration\": \"0:00:57\", \"run_number\": 18, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-11-04T03:16:01.827809Z\", \"is_reused\": \"\"}, {\"run_id\": \"5a59567e-0307-4b24-88dd-4ea455d3a39c\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-11-04T03:18:22.966891Z\", \"created_time\": \"2021-11-04T03:18:08.317137Z\", \"end_time\": \"2021-11-04T03:19:01.48017Z\", \"duration\": \"0:00:53\", \"run_number\": 19, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-11-04T03:18:08.317137Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-11-04 03:16:01Z] Submitting 1 runs, first five are: 64608749:b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\\n[2021-11-04 03:18:07Z] Completing processing run id b8fe99c2-83df-432f-b22e-c6cd0f3ccc32.\\n[2021-11-04 03:18:08Z] Submitting 1 runs, first five are: 5ee5571b:5a59567e-0307-4b24-88dd-4ea455d3a39c\\n[2021-11-04 03:20:11Z] Completing processing run id 5a59567e-0307-4b24-88dd-4ea455d3a39c.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"1a540207\": {\"node_id\": \"1a540207\", \"name\": \"telecom dataset\"}}, \"module_nodes\": {\"64608749\": {\"node_id\": \"64608749\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\"}, \"5ee5571b\": {\"node_id\": \"5ee5571b\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"5a59567e-0307-4b24-88dd-4ea455d3a39c\"}}, \"edges\": [{\"source_node_id\": \"1a540207\", \"source_node_name\": \"telecom dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"64608749\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"64608749\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data_folder\", \"target_name\": \"prepped_data_folder\", \"dst_node_id\": \"5ee5571b\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-11-04T03:16:18.770104Z\", \"created_time\": \"2021-11-04T03:16:01.827809Z\", \"end_time\": \"2021-11-04T03:16:59.194981Z\", \"duration\": \"0:00:57\", \"run_number\": 18, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-11-04T03:16:01.827809Z\", \"is_reused\": \"\"}, {\"run_id\": \"5a59567e-0307-4b24-88dd-4ea455d3a39c\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-11-04T03:18:22.966891Z\", \"created_time\": \"2021-11-04T03:18:08.317137Z\", \"end_time\": \"2021-11-04T03:19:01.48017Z\", \"duration\": \"0:00:53\", \"run_number\": 19, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-11-04T03:18:08.317137Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.35.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 77ca1a29-67ff-41fd-842d-11f5761c3727\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/77ca1a29-67ff-41fd-842d-11f5761c3727?wsid=/subscriptions/6d705e60-c254-4179-9abe-b484e8ac71ef/resourcegroups/MLOP/workspaces/MLOP_16&tid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32?wsid=/subscriptions/6d705e60-c254-4179-9abe-b484e8ac71ef/resourcegroups/MLOP/workspaces/MLOP_16&tid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6\n",
      "StepRun( Prepare Data ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      "========================================================================================================================\n",
      "2021-11-04T03:16:19Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=21863 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-11-04T03:16:20Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore\n",
      "2021-11-04T03:16:20Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:16:20Z Starting output-watcher...\n",
      "2021-11-04T03:16:20Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-11-04T03:16:20Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-11-04T03:16:20Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a\n",
      "Digest: sha256:67fbbc56d795817476a9fc9583a25817ec5605bc8547aa5017bc4bb75498e50e\n",
      "Status: Image is up to date for 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a:latest\n",
      "4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a:latest\n",
      "2021-11-04T03:16:20Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:16:21Z Check if container b8fe99c2-83df-432f-b22e-c6cd0f3ccc32 already exist exited with 0, \n",
      "\n",
      "7464d186a6c248ce7e227b39d7d1490a968f32d2c895bddf4fad71e22706d9e9\n",
      "2021-11-04T03:16:21Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-11-04T03:16:21Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-19ce689cd6064469efe3dfb9efb276fc-9f3f95e217c70885-01 -sshRequired=false] \n",
      "2021/11/04 03:16:21 Got JobInfoJson from env\n",
      "2021/11/04 03:16:21 Starting App Insight Logger for task:  containerSetup\n",
      "2021/11/04 03:16:21 Version: 3.0.01755.0003 Branch: .SourceBranch Commit: 66828d8\n",
      "2021/11/04 03:16:21 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/11/04 03:16:21 Starting infiniband setup\n",
      "2021/11/04 03:16:21 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/11/04 03:16:21 Returning Python Version as 3.6\n",
      "2021/11/04 03:16:21 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/11/04 03:16:21 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021-11-04T03:16:21Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/11/04 03:16:21 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/11/04 03:16:21 Not setting up Infiniband in Container\n",
      "2021/11/04 03:16:21 Not setting up Infiniband in Container\n",
      "2021-11-04T03:16:21Z Not setting up Infiniband in Container\n",
      "2021/11/04 03:16:21 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/11/04 03:16:21 Returning Python Version as 3.6\n",
      "2021/11/04 03:16:21 sshd inside container not required for job, skipping setup.\n",
      "2021/11/04 03:16:21 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "2021/11/04 03:16:21 App Insight Client has already been closed\n",
      "2021/11/04 03:16:21 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-11-04T03:16:21Z Starting docker container succeeded.\n",
      "2021-11-04T03:16:25Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:16:25Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:16:25Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/11/04 03:16:19 Got JobInfoJson from env\n",
      ">>>   2021/11/04 03:16:19 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/11/04 03:16:19 Version: 3.0.01755.0003 Branch: .SourceBranch Commit: 66828d8\n",
      ">>>   2021/11/04 03:16:19 Got JobInfoJson from env\n",
      ">>>   2021/11/04 03:16:19 runtime.GOOS linux\n",
      ">>>   2021/11/04 03:16:19 Checking if '/tmp' exists\n",
      ">>>   2021/11/04 03:16:19 Reading dyanamic configs\n",
      ">>>   2021/11/04 03:16:19 Container sas url: https://baiscriptseastusprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=gCpFfTbL8hPl%2BzV43hBdfOZC4SuKqZoJraIo10S4%2FYw%3D\n",
      ">>>   2021/11/04 03:16:19 Starting Azsecpack installation on machine: 5c1c141ad3dd45539ee5026eb037f014000000#83b02c92-5f26-48ed-9e5b-6c2fca46a8e6#6d705e60-c254-4179-9abe-b484e8ac71ef#mlop#mlop_16#mlop-test#tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d\n",
      ">>>   2021/11/04 03:16:19 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n",
      ">>>   2021/11/04 03:16:19 Azsecpack installation directory: /mnt/batch/tasks/startup/wd/az_resource, Is Azsecpack installer on host: true. Is Azsecpack installation enabled: false,\n",
      ">>>   2021/11/04 03:16:19 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n",
      ">>>   2021/11/04 03:16:19 Turning off azsecpack, if it is already running\n",
      ">>>   2021/11/04 03:16:19 Start deleting Azsecpack installation cronjob...\n",
      ">>>   2021/11/04 03:16:19 Start checking if Azsecpack is running...\n",
      ">>>   2021/11/04 03:16:19 Azsecpack is not running. No need to stop Azsecpack processes.\n",
      ">>>   2021/11/04 03:16:19 bypass systemd resolved\n",
      ">>>   2021/11/04 03:16:19 Cluster Subscription Id: 6d705e60-c254-4179-9abe-b484e8ac71ef\n",
      ">>>   2021/11/04 03:16:19 Cluster Workspace Name: mlop_16\n",
      ">>>   2021/11/04 03:16:19 Cluster Name: mlop-test\n",
      ">>>   2021/11/04 03:16:19 VMsize: standard_ds11_v2\n",
      ">>>   2021/11/04 03:16:19 GPU Count: 0\n",
      ">>>   2021/11/04 03:16:19 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/11/04 03:16:19 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:19 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:19 Get GPU count failed with err: The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command., \n",
      ">>>   2021/11/04 03:16:19 AMLComputeXDSEndpoint:  https://eastus.cert.api.azureml.ms/xdsbatchai\n",
      ">>>   2021/11/04 03:16:19 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/11/04 03:16:19 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/config\n",
      ">>>   2021/11/04 03:16:19 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/11/04 03:16:19 Starting identity responder.\n",
      ">>>   2021/11/04 03:16:19 Starting identity responder.\n",
      ">>>   2021/11/04 03:16:19 Logfile used for identity responder: /mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/IdentityResponderLog-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:16:19 Logfile used for identity responder: /mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/IdentityResponderLog-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:16:19 Started Identity Responder for job.\n",
      ">>>   2021/11/04 03:16:19 Started Identity Responder for job.\n",
      ">>>   2021/11/04 03:16:19 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd\n",
      ">>>   2021/11/04 03:16:19 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/shared\n",
      ">>>   2021/11/04 03:16:19 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:19 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/11/04 03:16:19 Mounting job level file systems\n",
      ">>>   2021/11/04 03:16:19 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts\n",
      ">>>   2021/11/04 03:16:19 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/11/04 03:16:19 Datastore credentials file not found, skipping.\n",
      ">>>   2021/11/04 03:16:19 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/config/.master.runtimesastokens\n",
      ">>>   2021/11/04 03:16:19 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/11/04 03:16:19 NFS mount is not enabled\n",
      ">>>   2021/11/04 03:16:19 No Azure File Shares configured\n",
      ">>>   2021/11/04 03:16:19 Mounting blob file systems\n",
      ">>>   2021/11/04 03:16:19 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/11/04 03:16:19 Mounting azureml-blobstore-4973babd-dbf8-4ce7-a40d-29f7e9b80686 container from mlop16storagedda754c1b3d account at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore\n",
      ">>>   2021/11/04 03:16:19 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/11/04 03:16:19 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/11/04 03:16:19 Blobfuse cache size set to 21863 MB.\n",
      ">>>   2021/11/04 03:16:19 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=21863 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/11/04 03:16:20 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore\n",
      ">>>   2021/11/04 03:16:20 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore\n",
      ">>>   2021/11/04 03:16:20 Successfully mounted azureml-blobstore-4973babd-dbf8-4ce7-a40d-29f7e9b80686 container from mlop16storagedda754c1b3d account at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore\n",
      ">>>   2021/11/04 03:16:20 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:20 No unmanaged file systems configured\n",
      ">>>   2021/11/04 03:16:20 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:20 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:20 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:20 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/11/04 03:16:20 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:20 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:20 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:20 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:20 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs\n",
      ">>>   2021/11/04 03:16:20 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d\n",
      ">>>   2021/11/04 03:16:20 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:16:20 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:20 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs\n",
      ">>>   2021/11/04 03:16:20 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs\n",
      ">>>   2021/11/04 03:16:20 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs\n",
      ">>>   2021/11/04 03:16:20 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d\n",
      ">>>   2021/11/04 03:16:20 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:16:20 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs\n",
      ">>>   2021/11/04 03:16:20 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs\n",
      ">>>   2021/11/04 03:16:20 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/outputs\n",
      ">>>   2021/11/04 03:16:20 Starting output-watcher...\n",
      ">>>   2021/11/04 03:16:20 Single file input dataset is enabled.\n",
      ">>>   2021/11/04 03:16:20 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
      ">>>   2021/11/04 03:16:20 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
      ">>>   2021/11/04 03:16:20 SidecarEnabled:: sidecar not enabled\n",
      ">>>   2021/11/04 03:16:20 Start to pulling docker image: 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a\n",
      ">>>   2021/11/04 03:16:20 Start pull docker image: 4973babddbf84ce7a40d29f7e9b80686.azurecr.io\n",
      ">>>   2021/11/04 03:16:20 Getting credentials for image 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a with url 4973babddbf84ce7a40d29f7e9b80686.azurecr.io\n",
      ">>>   2021/11/04 03:16:20 Container registry is ACR.\n",
      ">>>   2021/11/04 03:16:20 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/11/04 03:16:20 Getting ACR Credentials from EMS for environment telecom-pipeline-env:1\n",
      ">>>   2021/11/04 03:16:20 Requesting XDS for registry details.\n",
      ">>>   2021/11/04 03:16:20 Attempt 1 of http call to https://eastus.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/6d705e60-c254-4179-9abe-b484e8ac71ef/resourceGroups/mlop/workspaces/mlop_16/clusters/mlop-test/nodes/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d?api-version=2018-02-01\n",
      ">>>   2021/11/04 03:16:20 Got container registry details from credentials service for registry address: 4973babddbf84ce7a40d29f7e9b80686.azurecr.io.\n",
      ">>>   2021/11/04 03:16:20 Writing ACR Details to file...\n",
      ">>>   2021/11/04 03:16:20 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/11/04 03:16:20 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/11/04 03:16:20 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/11/04 03:16:20 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/11/04 03:16:20 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/11/04 03:16:20 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/11/04 03:16:20 EMS returned 4973babddbf84ce7a40d29f7e9b80686.azurecr.io for environment telecom-pipeline-env\n",
      ">>>   2021/11/04 03:16:20 Save docker credentials for image 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a in /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/docker_login_E4D7F663B359E4EA\n",
      ">>>   2021/11/04 03:16:20 Start login to the docker registry\n",
      ">>>   2021/11/04 03:16:20 Successfully logged into the docker registry.\n",
      ">>>   2021/11/04 03:16:20 Start run pull docker image command\n",
      ">>>   2021/11/04 03:16:20 Pull docker image succeeded.\n",
      ">>>   2021/11/04 03:16:20 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/docker_login_E4D7F663B359E4EA\n",
      ">>>   2021/11/04 03:16:20 Pull docker image time: 401.698045ms\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:20 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:20 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:20 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:20 Setting the memory limit for docker container to be 13674 MB\n",
      ">>>   2021/11/04 03:16:20 The env variable file size is 41078 bytes\n",
      ">>>   2021/11/04 03:16:20 Creating parent cgroup 'b8fe99c2-83df-432f-b22e-c6cd0f3ccc32' for Containers used in Job\n",
      ">>>   2021/11/04 03:16:20 Add parent cgroup 'b8fe99c2-83df-432f-b22e-c6cd0f3ccc32' to container 'b8fe99c2-83df-432f-b22e-c6cd0f3ccc32'\n",
      ">>>   2021/11/04 03:16:20 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/11/04 03:16:20 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,b8fe99c2-83df-432f-b22e-c6cd0f3ccc32,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/certs:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13674m,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/config/.batchai.envlist,--cgroup-parent=/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/,--shm-size,2g\n",
      ">>>   2021/11/04 03:16:20 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/11/04 03:16:20 the binding /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32 \n",
      ">>>   2021/11/04 03:16:20 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,b8fe99c2-83df-432f-b22e-c6cd0f3ccc32,-m,13674m,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/config/.batchai.envlist,--cgroup-parent=/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32,-v,/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd,-v,/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/certs:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/certs\n",
      ">>>   2021/11/04 03:16:20 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name b8fe99c2-83df-432f-b22e-c6cd0f3ccc32 -m 13674m -w /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/config/.batchai.envlist --cgroup-parent=/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32 -v /mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd -v /mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/certs:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/certs -d -it --privileged --net=host 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a\n",
      ">>>   2021/11/04 03:16:21 Check if container b8fe99c2-83df-432f-b22e-c6cd0f3ccc32 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:21 Check if container b8fe99c2-83df-432f-b22e-c6cd0f3ccc32 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:21 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/11/04 03:16:21 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/11/04 03:16:21 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-19ce689cd6064469efe3dfb9efb276fc-9f3f95e217c70885-01 -sshRequired=false] \n",
      ">>>   2021/11/04 03:16:21 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-19ce689cd6064469efe3dfb9efb276fc-9f3f95e217c70885-01 -sshRequired=false] \n",
      ">>>   2021/11/04 03:16:21 Container ssh is not required for job type.\n",
      ">>>   2021/11/04 03:16:21 Starting docker container succeeded.\n",
      ">>>   2021/11/04 03:16:21 Starting docker container succeeded.\n",
      ">>>   2021/11/04 03:16:21 Disk space after starting docker container: 23317MB\n",
      ">>>   2021/11/04 03:16:21 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
      ">>>   2021/11/04 03:16:21 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
      ">>>   2021/11/04 03:16:21 SidecarEnabled:: sidecar not enabled\n",
      ">>>   2021/11/04 03:16:21 Begin execution of runSpecialJobTask\n",
      ">>>   2021/11/04 03:16:21 Creating directory at $AZUREML_LOGDIRECTORY_PATH\n",
      ">>>   2021/11/04 03:16:21 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-logs\n",
      ">>>   2021/11/04 03:16:21 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs\n",
      ">>>   2021/11/04 03:16:21 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"71f5e182-3b66-4de0-bba2-aafb03fcf1ae\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/11/04 03:16:21 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs/65_job_prep-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:16:21 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs/65_job_prep-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:16:21 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32;/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"71f5e182-3b66-4de0-bba2-aafb03fcf1ae\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/11/04 03:16:21 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/11/04 03:16:21 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-19ce689cd6064469efe3dfb9efb276fc-7f08c695b1027e57-01 -t b8fe99c2-83df-432f-b22e-c6cd0f3ccc32 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32;/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/mounts/workspaceblobstore/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"71f5e182-3b66-4de0-bba2-aafb03fcf1ae\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/11/04 03:16:24 Attempt 1 of http call to https://eastus.api.azureml.ms/history/v1.0/private/subscriptions/6d705e60-c254-4179-9abe-b484e8ac71ef/resourceGroups/MLOP/providers/Microsoft.MachineLearningServices/workspaces/MLOP_16/runs/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/spans\n",
      ">>>   2021/11/04 03:16:25 containerName:b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:25 sidecar containerName:b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:25 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:25 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:25 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:25 sidecar dockerLauncher:docker\n",
      ">>>   2021/11/04 03:16:25 sidecarContainerId:7464d186a6c248ce7e227b39d7d1490a968f32d2c895bddf4fad71e22706d9e9\n",
      ">>>   2021/11/04 03:16:25 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:25 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:25 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:25 Docker logs for b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:22.300616] Entering job preparation.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:23.953702] Starting job preparation.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:23.953758] Extracting the control code.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:23.954607] Starting extract_project.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:23.954715] Starting to extract zip file.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:23.975787] Finished extracting zip file.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:23.979683] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:23.979783] Start fetching snapshots.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:23.979860] Start fetching snapshot.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:23.979876] Retrieving project from snapshot: 71f5e182-3b66-4de0-bba2-aafb03fcf1ae\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 44\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:24.382214] Finished fetching snapshot.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:24.382255] Finished fetching snapshots.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:24.382346] Finished extract_project.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:24.382495] Finished fetching and extracting the control code.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:24.387154] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:24.388393] Start run_history_prep.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:24.401722] Entering context manager injector.\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: Acquired lockfile /tmp/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32-datastore.lock to downloading input data references\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:24.867982] downloadDataStore completed\n",
      ">>>   2021/11/04 03:16:25 runSpecialJobTask: preparation: [2021-11-04T03:16:24.871160] Job preparation is complete.\n",
      ">>>   2021/11/04 03:16:25 DockerSideCarContainerLogs:\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:25 DockerSideCarContainerLogs End\n",
      ">>>   2021/11/04 03:16:25 Execution of runSpecialJobTask completed\n",
      ">>>   2021/11/04 03:16:25 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/11/04 03:16:25 Process Exiting with Code:  0\n",
      ">>>   2021/11/04 03:16:25 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      ">>>   \n",
      "2021-11-04T03:16:25Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:16:25Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:16:25Z 127.0.0.1 slots=2 max-slots=2\n",
      "2021-11-04T03:16:26Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-04T03:16:47Z job exited with code 0\n",
      "2021-11-04T03:16:47Z Executing 'JobRelease task' on 10.0.0.4\n",
      "2021-11-04T03:16:49Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:16:49Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:16:49Z JobRelease task succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/11/04 03:16:47 Got JobInfoJson from env\n",
      ">>>   2021/11/04 03:16:47 Starting App Insight Logger for task:  jobRelease\n",
      ">>>   2021/11/04 03:16:47 Version: 3.0.01755.0003 Branch: .SourceBranch Commit: 66828d8\n",
      ">>>   2021/11/04 03:16:47 Got JobInfoJson from env\n",
      ">>>   2021/11/04 03:16:47 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
      ">>>   2021/11/04 03:16:47 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
      ">>>   2021/11/04 03:16:47 SidecarEnabled:: sidecar not enabled\n",
      ">>>   2021/11/04 03:16:47 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs\n",
      ">>>   2021/11/04 03:16:47 runSpecialJobTask: Raw cmd for postprocessing is passed is: export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python $AZ_BATCHAI_JOB_TEMP/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-setup/job_release.py -i DataStoreCopy:context_managers.DataStores\n",
      ">>>   2021/11/04 03:16:47 runSpecialJobTask: stdout path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs/75_job_post-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:16:47 runSpecialJobTask: stderr path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml_compute_logs/75_job_post-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:16:47 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32;export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python $AZ_BATCHAI_JOB_TEMP/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-setup/job_release.py -i DataStoreCopy:context_managers.DataStores\n",
      ">>>   2021/11/04 03:16:47 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/11/04 03:16:47 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-19ce689cd6064469efe3dfb9efb276fc-7da93d1d4f949958-01 -t b8fe99c2-83df-432f-b22e-c6cd0f3ccc32 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/b8fe99c2-83df-432f-b_43978fc3-9789-42bf-8f67-b5bcd1118375/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/wd/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32;export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python $AZ_BATCHAI_JOB_TEMP/azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-setup/job_release.py -i DataStoreCopy:context_managers.DataStores\n",
      ">>>   2021/11/04 03:16:48 containerName:b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:48 sidecar containerName:b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   2021/11/04 03:16:49 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:49 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:49 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:49 sidecar dockerLauncher:docker\n",
      ">>>   2021/11/04 03:16:49 sidecarContainerId:7464d186a6c248ce7e227b39d7d1490a968f32d2c895bddf4fad71e22706d9e9\n",
      ">>>   2021/11/04 03:16:49 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:49 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:49 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:16:49 Docker logs for b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: job postprocessing exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:47.391399] Entering job release\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.287971] Starting job release\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.288836] Logging experiment finalizing status in history service.\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: Starting the daemon thread to refresh tokens in background for process with pid = 348\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.292327] job release stage : upload_datastore starting...\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.299721] Entering context manager injector.\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.303129] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.303630] job release stage : copy_batchai_cached_logs starting...\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.303740] job release stage : execute_job_release starting...\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.304064] job release stage : copy_batchai_cached_logs completed...\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.325247] job release stage : upload_datastore completed...\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.388475] job release stage : send_run_telemetry starting...\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.414294] get vm size and vm region successfully.\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.423344] get compute meta data successfully.\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.547554] job release stage : execute_job_release completed...\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.697037] post artifact meta request successfully.\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.730012] upload compute record artifact successfully.\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.730092] job release stage : send_run_telemetry completed...\n",
      ">>>   2021/11/04 03:16:49 runSpecialJobTask: postprocessing: [2021-11-04T03:16:48.730343] Job release is complete\n",
      ">>>   2021/11/04 03:16:49 DockerSideCarContainerLogs:\n",
      ">>>   \n",
      ">>>   2021/11/04 03:16:49 DockerSideCarContainerLogs End\n",
      ">>>   2021/11/04 03:16:49 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      ">>>   2021/11/04 03:16:49 App Insight Client has already been closed\n",
      ">>>   2021/11/04 03:16:49 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   \n",
      "2021-11-04T03:16:49Z Executing 'Job environment clean-up' on 10.0.0.4\n",
      "2021-11-04T03:16:50Z Removing container b8fe99c2-83df-432f-b22e-c6cd0f3ccc32 exited with 0, b8fe99c2-83df-432f-b22e-c6cd0f3ccc32\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      "===============================================================================================================\n",
      "[2021-11-04T03:16:47.391399] Entering job release\n",
      "[2021-11-04T03:16:48.287971] Starting job release\n",
      "[2021-11-04T03:16:48.288836] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 348\n",
      "[2021-11-04T03:16:48.292327] job release stage : upload_datastore starting...\n",
      "[2021-11-04T03:16:48.299721] Entering context manager injector.\n",
      "[2021-11-04T03:16:48.303129] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-11-04T03:16:48.303630] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-11-04T03:16:48.303740] job release stage : execute_job_release starting...\n",
      "[2021-11-04T03:16:48.304064] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-11-04T03:16:48.325247] job release stage : upload_datastore completed...\n",
      "[2021-11-04T03:16:48.388475] job release stage : send_run_telemetry starting...\n",
      "[2021-11-04T03:16:48.414294] get vm size and vm region successfully.\n",
      "[2021-11-04T03:16:48.423344] get compute meta data successfully.\n",
      "[2021-11-04T03:16:48.547554] job release stage : execute_job_release completed...\n",
      "[2021-11-04T03:16:48.697037] post artifact meta request successfully.\n",
      "[2021-11-04T03:16:48.730012] upload compute record artifact successfully.\n",
      "[2021-11-04T03:16:48.730092] job release stage : send_run_telemetry completed...\n",
      "[2021-11-04T03:16:48.730343] Job release is complete\n",
      "\n",
      "StepRun(Prepare Data) Execution Summary\n",
      "========================================\n",
      "StepRun( Prepare Data ) Status: Finished\n",
      "{'runId': 'b8fe99c2-83df-432f-b22e-c6cd0f3ccc32', 'target': 'mlop-test', 'status': 'Completed', 'startTimeUtc': '2021-11-04T03:16:18.770104Z', 'endTimeUtc': '2021-11-04T03:16:59.194981Z', 'services': {}, 'properties': {'ContentSnapshotId': '71f5e182-3b66-4de0-bba2-aafb03fcf1ae', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '880b1623-cd7c-4a40-9ece-9f6d512145be', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '64608749', 'azureml.pipelinerunid': '77ca1a29-67ff-41fd-842d-11f5761c3727', 'azureml.pipeline': '77ca1a29-67ff-41fd-842d-11f5761c3727', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'a89d954d-fbed-4f59-8ea4-a8f500a1415a'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'prep_telecom.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', '$AZUREML_DATAREFERENCE_prepped_data_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'mlop-test', 'dataReferences': {'prepped_data_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/prepped_data_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': 'a89d954d-fbed-4f59-8ea4-a8f500a1415a', 'name': None, 'version': '2'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'telecom-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'azureml-dataprep[pandas]', 'pyarrow']}, 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip'], 'name': 'azureml_37123770cfa02a1fe00f423fa57ee472'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210922.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-logs/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt?sv=2019-07-07&sr=b&sig=eFdjaasGZCHCklVEBUI68DXze1bheJb0hHiPPfBzHpM%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T22%3A26%3A38Z&ske=2021-11-05T06%3A36%3A38Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'azureml-logs/65_job_prep-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-logs/65_job_prep-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt?sv=2019-07-07&sr=b&sig=VMosnXFFJzDegK8RIBXwFQA0Dm98jRlk7MFtH2NI5Ro%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T22%3A26%3A38Z&ske=2021-11-05T06%3A36%3A38Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=4%2FBu9DjXc2h4g064UxjSiOWUWGLtkNE9D9zqo0DSFeo%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T22%3A26%3A38Z&ske=2021-11-05T06%3A36%3A38Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'azureml-logs/75_job_post-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-logs/75_job_post-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt?sv=2019-07-07&sr=b&sig=WNMKZQs9Kwd715NRgVcH6Ex3L6nF1CLA7zM61Fq%2FS5s%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T22%3A26%3A38Z&ske=2021-11-05T06%3A36%3A38Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'azureml-logs/process_info.json': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=brffzC9q3TSH3wpBZTFl%2BfzxFlBIwoClkSdsC5lTcs0%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T22%3A26%3A38Z&ske=2021-11-05T06%3A36%3A38Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'azureml-logs/process_status.json': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=T4zXbSIH%2FsWUM7%2B%2F718l%2F3G7oqWQj1EbodX9C7L2GKE%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T22%3A26%3A38Z&ske=2021-11-05T06%3A36%3A38Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'logs/azureml/95_azureml.log': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/95_azureml.log?sv=2019-07-07&sr=b&sig=nurTUZqGjC5TMShkH8a9m6x3FGhE4YS%2BmA9ncNki5ac%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T01%3A21%3A35Z&ske=2021-11-05T09%3A31%3A35Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=EO0qI1Dgkq6F7%2BOIT%2F1nlKrXLmI5Y7UeeIflvGdvNLI%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T01%3A21%3A35Z&ske=2021-11-05T09%3A31%3A35Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=PrbM9sxBw5uIl6oR6hZ9NeFTjUYxOmeIafRzSe6RrXs%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T01%3A21%3A35Z&ske=2021-11-05T09%3A31%3A35Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=iilKonPzrf0h21znkUQelHFYYr0ntAbt9o4AckIR9jc%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T01%3A21%3A35Z&ske=2021-11-05T09%3A31%3A35Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=jEEKt69sDjKANzr4rU7tLnqRIvcJxaehkNWfpLzr4O0%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T01%3A21%3A35Z&ske=2021-11-05T09%3A31%3A35Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=iDISBagzwB7PRI4ZMhl8xSNssB7zRQbd049AsE%2B4%2Fsk%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T01%3A21%3A35Z&ske=2021-11-05T09%3A31%3A35Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=Sgol6ZUliU5uMoKPH05O8ieXympDo%2BiKwitGihe5%2BdA%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T01%3A21%3A35Z&ske=2021-11-05T09%3A31%3A35Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=lGIVLhnXUVNhLF0lr4tkTe6rsRjI6VSiu7pN%2Bio%2FQ8k%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T01%3A21%3A35Z&ske=2021-11-05T09%3A31%3A35Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A52Z&se=2021-11-04T11%3A16%3A52Z&sp=r'}, 'submittedBy': 'Lingyi Zhao'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: 5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/5a59567e-0307-4b24-88dd-4ea455d3a39c?wsid=/subscriptions/6d705e60-c254-4179-9abe-b484e8ac71ef/resourcegroups/MLOP/workspaces/MLOP_16&tid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6\n",
      "StepRun( Train and Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      "========================================================================================================================\n",
      "2021-11-04T03:18:22Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=21863 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      "2021-11-04T03:18:22Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore\n",
      "2021-11-04T03:18:23Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:18:23Z Starting output-watcher...\n",
      "2021-11-04T03:18:23Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-11-04T03:18:23Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-11-04T03:18:23Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a\n",
      "Digest: sha256:67fbbc56d795817476a9fc9583a25817ec5605bc8547aa5017bc4bb75498e50e\n",
      "Status: Image is up to date for 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a:latest\n",
      "4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a:latest\n",
      "2021-11-04T03:18:23Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:18:24Z Check if container 5a59567e-0307-4b24-88dd-4ea455d3a39c already exist exited with 0, \n",
      "\n",
      "e87c83720db262dcee9376c9a19ef338d43d684fa0b63426a69ff4b8b3aefb29\n",
      "2021-11-04T03:18:24Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-11-04T03:18:24Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-94af3b2715a6011cf0eb907d087fb268-becee0e4bfba40dc-01 -sshRequired=false] \n",
      "2021/11/04 03:18:24 Got JobInfoJson from env\n",
      "2021/11/04 03:18:24 Starting App Insight Logger for task:  containerSetup\n",
      "2021/11/04 03:18:24 Version: 3.0.01755.0003 Branch: .SourceBranch Commit: 66828d8\n",
      "2021/11/04 03:18:24 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/11/04 03:18:24 Starting infiniband setup\n",
      "2021/11/04 03:18:24 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/11/04 03:18:24 Returning Python Version as 3.6\n",
      "2021-11-04T03:18:24Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021-11-04T03:18:24Z Not setting up Infiniband in Container\n",
      "2021/11/04 03:18:24 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/11/04 03:18:24 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/11/04 03:18:24 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/11/04 03:18:24 Not setting up Infiniband in Container\n",
      "2021/11/04 03:18:24 Not setting up Infiniband in Container\n",
      "2021/11/04 03:18:24 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/11/04 03:18:24 Returning Python Version as 3.6\n",
      "2021/11/04 03:18:24 sshd inside container not required for job, skipping setup.\n",
      "2021/11/04 03:18:24 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      "2021/11/04 03:18:24 App Insight Client has already been closed\n",
      "2021/11/04 03:18:24 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-11-04T03:18:24Z Starting docker container succeeded.\n",
      "2021-11-04T03:18:27Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:18:27Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:18:29Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/11/04 03:18:22 Got JobInfoJson from env\n",
      ">>>   2021/11/04 03:18:22 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/11/04 03:18:22 Version: 3.0.01755.0003 Branch: .SourceBranch Commit: 66828d8\n",
      ">>>   2021/11/04 03:18:22 Got JobInfoJson from env\n",
      ">>>   2021/11/04 03:18:22 runtime.GOOS linux\n",
      ">>>   2021/11/04 03:18:22 Checking if '/tmp' exists\n",
      ">>>   2021/11/04 03:18:22 Reading dyanamic configs\n",
      ">>>   2021/11/04 03:18:22 Container sas url: https://baiscriptseastusprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=gCpFfTbL8hPl%2BzV43hBdfOZC4SuKqZoJraIo10S4%2FYw%3D\n",
      ">>>   2021/11/04 03:18:22 Starting Azsecpack installation on machine: 5c1c141ad3dd45539ee5026eb037f014000000#83b02c92-5f26-48ed-9e5b-6c2fca46a8e6#6d705e60-c254-4179-9abe-b484e8ac71ef#mlop#mlop_16#mlop-test#tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d\n",
      ">>>   2021/11/04 03:18:22 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n",
      ">>>   2021/11/04 03:18:22 Azsecpack installation directory: /mnt/batch/tasks/startup/wd/az_resource, Is Azsecpack installer on host: true. Is Azsecpack installation enabled: false,\n",
      ">>>   2021/11/04 03:18:22 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n",
      ">>>   2021/11/04 03:18:22 Turning off azsecpack, if it is already running\n",
      ">>>   2021/11/04 03:18:22 Start deleting Azsecpack installation cronjob...\n",
      ">>>   2021/11/04 03:18:22 Start checking if Azsecpack is running...\n",
      ">>>   2021/11/04 03:18:22 Azsecpack is not running. No need to stop Azsecpack processes.\n",
      ">>>   2021/11/04 03:18:22 bypass systemd resolved\n",
      ">>>   2021/11/04 03:18:22 Cluster Subscription Id: 6d705e60-c254-4179-9abe-b484e8ac71ef\n",
      ">>>   2021/11/04 03:18:22 Cluster Workspace Name: mlop_16\n",
      ">>>   2021/11/04 03:18:22 Cluster Name: mlop-test\n",
      ">>>   2021/11/04 03:18:22 VMsize: standard_ds11_v2\n",
      ">>>   2021/11/04 03:18:22 GPU Count: 0\n",
      ">>>   2021/11/04 03:18:22 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/11/04 03:18:22 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:22 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:22 Get GPU count failed with err: The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command., \n",
      ">>>   2021/11/04 03:18:22 AMLComputeXDSEndpoint:  https://eastus.cert.api.azureml.ms/xdsbatchai\n",
      ">>>   2021/11/04 03:18:22 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/11/04 03:18:22 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/config\n",
      ">>>   2021/11/04 03:18:22 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/11/04 03:18:22 Starting identity responder.\n",
      ">>>   2021/11/04 03:18:22 Starting identity responder.\n",
      ">>>   2021/11/04 03:18:22 Logfile used for identity responder: /mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/IdentityResponderLog-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:18:22 Logfile used for identity responder: /mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/IdentityResponderLog-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:18:22 Started Identity Responder for job.\n",
      ">>>   2021/11/04 03:18:22 Started Identity Responder for job.\n",
      ">>>   2021/11/04 03:18:22 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd\n",
      ">>>   2021/11/04 03:18:22 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/shared\n",
      ">>>   2021/11/04 03:18:22 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:22 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/11/04 03:18:22 Mounting job level file systems\n",
      ">>>   2021/11/04 03:18:22 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts\n",
      ">>>   2021/11/04 03:18:22 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/11/04 03:18:22 Datastore credentials file not found, skipping.\n",
      ">>>   2021/11/04 03:18:22 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/config/.master.runtimesastokens\n",
      ">>>   2021/11/04 03:18:22 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/11/04 03:18:22 NFS mount is not enabled\n",
      ">>>   2021/11/04 03:18:22 No Azure File Shares configured\n",
      ">>>   2021/11/04 03:18:22 Mounting blob file systems\n",
      ">>>   2021/11/04 03:18:22 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/11/04 03:18:22 Mounting azureml-blobstore-4973babd-dbf8-4ce7-a40d-29f7e9b80686 container from mlop16storagedda754c1b3d account at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore\n",
      ">>>   2021/11/04 03:18:22 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/11/04 03:18:22 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/11/04 03:18:22 Blobfuse cache size set to 21863 MB.\n",
      ">>>   2021/11/04 03:18:22 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=21863 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/11/04 03:18:22 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore\n",
      ">>>   2021/11/04 03:18:22 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore\n",
      ">>>   2021/11/04 03:18:23 Successfully mounted azureml-blobstore-4973babd-dbf8-4ce7-a40d-29f7e9b80686 container from mlop16storagedda754c1b3d account at /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore\n",
      ">>>   2021/11/04 03:18:23 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:23 No unmanaged file systems configured\n",
      ">>>   2021/11/04 03:18:23 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:23 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:23 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:23 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/11/04 03:18:23 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:23 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:23 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:23 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs\n",
      ">>>   2021/11/04 03:18:23 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d\n",
      ">>>   2021/11/04 03:18:23 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:18:23 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs\n",
      ">>>   2021/11/04 03:18:23 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs\n",
      ">>>   2021/11/04 03:18:23 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs\n",
      ">>>   2021/11/04 03:18:23 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d\n",
      ">>>   2021/11/04 03:18:23 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:18:23 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs\n",
      ">>>   2021/11/04 03:18:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/logs\n",
      ">>>   2021/11/04 03:18:23 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/outputs\n",
      ">>>   2021/11/04 03:18:23 Starting output-watcher...\n",
      ">>>   2021/11/04 03:18:23 Single file input dataset is enabled.\n",
      ">>>   2021/11/04 03:18:23 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
      ">>>   2021/11/04 03:18:23 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
      ">>>   2021/11/04 03:18:23 SidecarEnabled:: sidecar not enabled\n",
      ">>>   2021/11/04 03:18:23 Start to pulling docker image: 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a\n",
      ">>>   2021/11/04 03:18:23 Start pull docker image: 4973babddbf84ce7a40d29f7e9b80686.azurecr.io\n",
      ">>>   2021/11/04 03:18:23 Getting credentials for image 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a with url 4973babddbf84ce7a40d29f7e9b80686.azurecr.io\n",
      ">>>   2021/11/04 03:18:23 Container registry is ACR.\n",
      ">>>   2021/11/04 03:18:23 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/11/04 03:18:23 Getting ACR Credentials from EMS for environment telecom-pipeline-env:1\n",
      ">>>   2021/11/04 03:18:23 Requesting XDS for registry details.\n",
      ">>>   2021/11/04 03:18:23 Attempt 1 of http call to https://eastus.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/6d705e60-c254-4179-9abe-b484e8ac71ef/resourceGroups/mlop/workspaces/mlop_16/clusters/mlop-test/nodes/tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d?api-version=2018-02-01\n",
      ">>>   2021/11/04 03:18:23 Got container registry details from credentials service for registry address: 4973babddbf84ce7a40d29f7e9b80686.azurecr.io.\n",
      ">>>   2021/11/04 03:18:23 Writing ACR Details to file...\n",
      ">>>   2021/11/04 03:18:23 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/11/04 03:18:23 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/11/04 03:18:23 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/11/04 03:18:23 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/11/04 03:18:23 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/11/04 03:18:23 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/11/04 03:18:23 EMS returned 4973babddbf84ce7a40d29f7e9b80686.azurecr.io for environment telecom-pipeline-env\n",
      ">>>   2021/11/04 03:18:23 Save docker credentials for image 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a in /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/docker_login_E2B85BA0632F8AB2\n",
      ">>>   2021/11/04 03:18:23 Start login to the docker registry\n",
      ">>>   2021/11/04 03:18:23 Successfully logged into the docker registry.\n",
      ">>>   2021/11/04 03:18:23 Start run pull docker image command\n",
      ">>>   2021/11/04 03:18:23 Pull docker image succeeded.\n",
      ">>>   2021/11/04 03:18:23 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/docker_login_E2B85BA0632F8AB2\n",
      ">>>   2021/11/04 03:18:23 Pull docker image time: 494.828235ms\n",
      ">>>   \n",
      ">>>   2021/11/04 03:18:23 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/04 03:18:23 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:23 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:23 Setting the memory limit for docker container to be 13674 MB\n",
      ">>>   2021/11/04 03:18:23 The env variable file size is 40377 bytes\n",
      ">>>   2021/11/04 03:18:23 Creating parent cgroup '5a59567e-0307-4b24-88dd-4ea455d3a39c' for Containers used in Job\n",
      ">>>   2021/11/04 03:18:23 Add parent cgroup '5a59567e-0307-4b24-88dd-4ea455d3a39c' to container '5a59567e-0307-4b24-88dd-4ea455d3a39c'\n",
      ">>>   2021/11/04 03:18:23 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/11/04 03:18:23 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,5a59567e-0307-4b24-88dd-4ea455d3a39c,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/certs:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13674m,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/wd:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/config/.batchai.envlist,--cgroup-parent=/5a59567e-0307-4b24-88dd-4ea455d3a39c/,--shm-size,2g\n",
      ">>>   2021/11/04 03:18:23 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/11/04 03:18:23 the binding /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c \n",
      ">>>   2021/11/04 03:18:23 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,5a59567e-0307-4b24-88dd-4ea455d3a39c,-m,13674m,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/config/.batchai.envlist,--cgroup-parent=/5a59567e-0307-4b24-88dd-4ea455d3a39c/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c,-v,/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/wd:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/wd,-v,/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/certs:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/certs\n",
      ">>>   2021/11/04 03:18:23 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 5a59567e-0307-4b24-88dd-4ea455d3a39c -m 13674m -w /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/config/.batchai.envlist --cgroup-parent=/5a59567e-0307-4b24-88dd-4ea455d3a39c/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c:/mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c -v /mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/wd:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/wd -v /mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/certs:/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/certs -d -it --privileged --net=host 4973babddbf84ce7a40d29f7e9b80686.azurecr.io/azureml/azureml_74b5d7b1bfec63ece12721fc9d263e9a\n",
      ">>>   2021/11/04 03:18:24 Check if container 5a59567e-0307-4b24-88dd-4ea455d3a39c already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/11/04 03:18:24 Check if container 5a59567e-0307-4b24-88dd-4ea455d3a39c already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/11/04 03:18:24 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/11/04 03:18:24 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/11/04 03:18:24 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-94af3b2715a6011cf0eb907d087fb268-becee0e4bfba40dc-01 -sshRequired=false] \n",
      ">>>   2021/11/04 03:18:24 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-94af3b2715a6011cf0eb907d087fb268-becee0e4bfba40dc-01 -sshRequired=false] \n",
      ">>>   2021/11/04 03:18:24 Container ssh is not required for job type.\n",
      ">>>   2021/11/04 03:18:24 Starting docker container succeeded.\n",
      ">>>   2021/11/04 03:18:24 Starting docker container succeeded.\n",
      ">>>   2021/11/04 03:18:24 Disk space after starting docker container: 23317MB\n",
      ">>>   2021/11/04 03:18:24 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n",
      ">>>   2021/11/04 03:18:24 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n",
      ">>>   2021/11/04 03:18:24 SidecarEnabled:: sidecar not enabled\n",
      ">>>   2021/11/04 03:18:24 Begin execution of runSpecialJobTask\n",
      ">>>   2021/11/04 03:18:24 Creating directory at $AZUREML_LOGDIRECTORY_PATH\n",
      ">>>   2021/11/04 03:18:24 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml-logs\n",
      ">>>   2021/11/04 03:18:24 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs\n",
      ">>>   2021/11/04 03:18:24 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"71f5e182-3b66-4de0-bba2-aafb03fcf1ae\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/11/04 03:18:24 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs/65_job_prep-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:18:24 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml_compute_logs/65_job_prep-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      ">>>   2021/11/04 03:18:24 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c;/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"71f5e182-3b66-4de0-bba2-aafb03fcf1ae\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/11/04 03:18:24 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/11/04 03:18:24 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-94af3b2715a6011cf0eb907d087fb268-fd343b3a6d82fa6a-01 -t 5a59567e-0307-4b24-88dd-4ea455d3a39c bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/53b6ba0b-36b0-4b86-87a1-1f6acbd63578/job-1/5a59567e-0307-4b24-8_fa782851-a352-4d51-b35a-78133ce8da58/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/wd/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c;/azureml-envs/azureml_37123770cfa02a1fe00f423fa57ee472/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlop_16/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c/mounts/workspaceblobstore/azureml/5a59567e-0307-4b24-88dd-4ea455d3a39c-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"71f5e182-3b66-4de0-bba2-aafb03fcf1ae\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/11/04 03:18:27 Attempt 1 of http call to https://eastus.api.azureml.ms/history/v1.0/private/subscriptions/6d705e60-c254-4179-9abe-b484e8ac71ef/resourceGroups/MLOP/providers/Microsoft.MachineLearningServices/workspaces/MLOP_16/runs/5a59567e-0307-4b24-88dd-4ea455d3a39c/spans\n",
      ">>>   2021/11/04 03:18:27 containerName:5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:27 sidecar containerName:5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   2021/11/04 03:18:27 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/04 03:18:27 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:27 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:27 sidecar dockerLauncher:docker\n",
      ">>>   2021/11/04 03:18:27 sidecarContainerId:e87c83720db262dcee9376c9a19ef338d43d684fa0b63426a69ff4b8b3aefb29\n",
      ">>>   2021/11/04 03:18:27 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/11/04 03:18:27 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:27 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/11/04 03:18:28 Docker logs for 5a59567e-0307-4b24-88dd-4ea455d3a39c\n",
      ">>>   \n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:25.136772] Entering job preparation.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:26.691712] Starting job preparation.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:26.691755] Extracting the control code.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:26.692421] Starting extract_project.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:26.692481] Starting to extract zip file.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:26.709435] Finished extracting zip file.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:26.713471] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:26.713523] Start fetching snapshots.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:26.713559] Start fetching snapshot.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:26.713636] Retrieving project from snapshot: 71f5e182-3b66-4de0-bba2-aafb03fcf1ae\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 45\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:27.151501] Finished fetching snapshot.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:27.151544] Finished fetching snapshots.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:27.151555] Finished extract_project.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:27.151829] Finished fetching and extracting the control code.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:27.155932] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:27.157926] Start run_history_prep.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:27.169575] Entering context manager injector.\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: Acquired lockfile /tmp/5a59567e-0307-4b24-88dd-4ea455d3a39c-datastore.lock to downloading input data references\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:27.639338] downloadDataStore completed\n",
      ">>>   2021/11/04 03:18:28 runSpecialJobTask: preparation: [2021-11-04T03:18:27.647406] Job preparation is complete.\n",
      ">>>   2021/11/04 03:18:28 DockerSideCarContainerLogs:\n",
      ">>>   \n",
      ">>>   2021/11/04 03:18:28 DockerSideCarContainerLogs End\n",
      ">>>   2021/11/04 03:18:28 Execution of runSpecialJobTask completed\n",
      ">>>   2021/11/04 03:18:28 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/11/04 03:18:28 Process Exiting with Code:  0\n",
      ">>>   2021/11/04 03:18:29 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n",
      ">>>   \n",
      "2021-11-04T03:18:29Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:18:29Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-11-04T03:18:29Z 127.0.0.1 slots=2 max-slots=2\n",
      "2021-11-04T03:18:29Z launching Custom job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt\n",
      "===============================================================================================================\n",
      "[2021-11-04T03:18:50.197121] Entering job release\n",
      "[2021-11-04T03:18:51.096351] Starting job release\n",
      "[2021-11-04T03:18:51.097799] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 136\n",
      "[2021-11-04T03:18:51.101834] job release stage : upload_datastore starting...\n",
      "[2021-11-04T03:18:51.109598] Entering context manager injector.\n",
      "[2021-11-04T03:18:51.109895] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-11-04T03:18:51.111730] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-11-04T03:18:51.111809] job release stage : execute_job_release starting...\n",
      "[2021-11-04T03:18:51.113498] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-11-04T03:18:51.145208] job release stage : upload_datastore completed...\n",
      "[2021-11-04T03:18:51.187659] job release stage : send_run_telemetry starting...\n",
      "[2021-11-04T03:18:51.222675] get vm size and vm region successfully.\n",
      "[2021-11-04T03:18:51.233582] get compute meta data successfully.\n",
      "[2021-11-04T03:18:51.401190] post artifact meta request successfully.\n",
      "[2021-11-04T03:18:51.421179] job release stage : execute_job_release completed...\n",
      "[2021-11-04T03:18:51.443044] upload compute record artifact successfully.\n",
      "[2021-11-04T03:18:51.443167] job release stage : send_run_telemetry completed...\n",
      "[2021-11-04T03:18:51.443611] Job release is complete\n",
      "\n",
      "StepRun(Train and Register Model) Execution Summary\n",
      "====================================================\n",
      "StepRun( Train and Register Model ) Status: Finished\n",
      "{'runId': '5a59567e-0307-4b24-88dd-4ea455d3a39c', 'target': 'mlop-test', 'status': 'Completed', 'startTimeUtc': '2021-11-04T03:18:22.966891Z', 'endTimeUtc': '2021-11-04T03:19:01.48017Z', 'services': {}, 'properties': {'ContentSnapshotId': '71f5e182-3b66-4de0-bba2-aafb03fcf1ae', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'b9b0fba6-d1aa-4d02-b35d-998a29b1f5da', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '5ee5571b', 'azureml.pipelinerunid': '77ca1a29-67ff-41fd-842d-11f5761c3727', 'azureml.pipeline': '77ca1a29-67ff-41fd-842d-11f5761c3727', 'azureml.pipelineComponent': 'masterescloud', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'train_rf.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-folder', '$AZUREML_DATAREFERENCE_prepped_data_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'mlop-test', 'dataReferences': {'prepped_data_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/b8fe99c2-83df-432f-b22e-c6cd0f3ccc32/prepped_data_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'telecom-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults', 'azureml-dataprep[pandas]', 'pyarrow']}, 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip'], 'name': 'azureml_37123770cfa02a1fe00f423fa57ee472'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210922.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml-logs/55_azureml-execution-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt?sv=2019-07-07&sr=b&sig=PLCIjxyH8%2BE1wuUFnDTvDlCGjwsHJT1fETJiVqxG5XE%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T23%3A56%3A24Z&ske=2021-11-05T08%3A06%3A24Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'azureml-logs/65_job_prep-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml-logs/65_job_prep-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt?sv=2019-07-07&sr=b&sig=HBcBHEaVN5w19PQGnu8CxR9WoUuYAHtDXrQPdXS48XI%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T23%3A56%3A24Z&ske=2021-11-05T08%3A06%3A24Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=bH1995cMEcwT56W5zcvpVs%2BPSPvKOlQ6S5RtRnuceKE%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T23%3A56%3A24Z&ske=2021-11-05T08%3A06%3A24Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'azureml-logs/75_job_post-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml-logs/75_job_post-tvmps_8a66c266e4089943ed1e8a0ce8ca21522ffc2741f61acdc21e8639d123ba8470_d.txt?sv=2019-07-07&sr=b&sig=H3mKfEHGtADSYy6JeJ0gZ7xMhlkhXFlQjDR%2BsUb4PM4%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T23%3A56%3A24Z&ske=2021-11-05T08%3A06%3A24Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'azureml-logs/process_info.json': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=uy%2F5uFKB%2FL0TKfS%2Fu0%2Bc6D%2FPnILyCkQSfbi3zCg%2BUnY%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T23%3A56%3A24Z&ske=2021-11-05T08%3A06%3A24Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'azureml-logs/process_status.json': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=aiPc9euyXvNYy%2FqGfw82I%2BC5zFJrxCo5tmgE5fjonT0%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-03T23%3A56%3A24Z&ske=2021-11-05T08%3A06%3A24Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'logs/azureml/96_azureml.log': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/96_azureml.log?sv=2019-07-07&sr=b&sig=%2FPvOdP0OUfWMnBwW64zRsX1363LWr5aqmTYRY1hygPY%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A34%3A59Z&ske=2021-11-05T08%3A44%3A59Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=afHgWNL8h37fFnJOtlH%2FeLKHf0vy66EmlOeDBTG1q20%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A34%3A59Z&ske=2021-11-05T08%3A44%3A59Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=fk6ujYHqIcz4wxLPqg0CSc68B%2BtLPas7ISdRhzVVWOs%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A34%3A59Z&ske=2021-11-05T08%3A44%3A59Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=ah9%2BZUC944aZD6CWNA1kJSsTKjiSZhfoueWlA0BbGKQ%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A34%3A59Z&ske=2021-11-05T08%3A44%3A59Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=sr1WHRlyxnqNc9wUWgwSN851NbeOJDITNT9I8PxIMVM%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A34%3A59Z&ske=2021-11-05T08%3A44%3A59Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.5a59567e-0307-4b24-88dd-4ea455d3a39c/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=JFUksVzh8TZWDQIZfqjofY2DN6fEq9osOddHDLZH9lE%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A34%3A59Z&ske=2021-11-05T08%3A44%3A59Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A08%3A54Z&se=2021-11-04T11%3A18%3A54Z&sp=r'}, 'submittedBy': 'Lingyi Zhao'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '77ca1a29-67ff-41fd-842d-11f5761c3727', 'status': 'Completed', 'startTimeUtc': '2021-11-04T03:16:00.419554Z', 'endTimeUtc': '2021-11-04T03:20:11.525167Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.77ca1a29-67ff-41fd-842d-11f5761c3727/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=5q%2B1DP2NdacH7G55kv86jPsFVEUqDBe2%2FT8RHQZo1o0%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A33%3A32Z&ske=2021-11-05T08%3A43%3A32Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A01Z&se=2021-11-04T11%3A16%3A01Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlop16storagedda754c1b3d.blob.core.windows.net/azureml/ExperimentRun/dcid.77ca1a29-67ff-41fd-842d-11f5761c3727/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=3Jf1iwzqo8uDF%2F7f78tX4uwBC%2B9dlHpW0td5HMrsd70%3D&skoid=b7ffea5a-3738-413d-837f-d86527db4a2f&sktid=83b02c92-5f26-48ed-9e5b-6c2fca46a8e6&skt=2021-11-04T00%3A33%3A32Z&ske=2021-11-05T08%3A43%3A32Z&sks=b&skv=2019-07-07&st=2021-11-04T03%3A06%3A01Z&se=2021-11-04T11%3A16%3A01Z&sp=r'}, 'submittedBy': 'Lingyi Zhao'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [train_step, register_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name = 'telecom-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
